{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Hugging Face](https://huggingface.co/)\n",
    "- [Spaces - Hugging Face](https://huggingface.co/spaces)\n",
    "- [HF-Mirror](https://hf-mirror.com/)\n",
    "- [HF LLM Course](https://huggingface.co/learn/llm-course/chapter1/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用 Pipeline 完成多种 NLP 任务是一个非常强大且高效的方法。它可以将多个独立的 NLP 模型串联起来，形成一个端到端的处理流程，从而解决更复杂的自然语言理解和生成问题。\n",
    "\n",
    "您可以利用 Pipeline 来完成以下多种 NLP 任务的组合：\n",
    "1. 文本分类与命名实体识别 (NER):\n",
    "> Pipeline: 文本分类器 -> NER 模型\n",
    "应用场景: 分析用户评论的情感，并识别评论中提到的产品名称、公司名称等实体。\n",
    "示例流程:\n",
    "输入用户评论：“我非常喜欢这款苹果手机，它的电池续航很棒！”\n",
    "文本分类器分析情感为“积极”。\n",
    "NER 模型识别出“苹果手机”为产品实体，“电池续航”为属性。\n",
    "输出：情感：积极，实体：[{'entity': '产品', 'value': '苹果手机'}, {'entity': '属性', 'value': '电池续航'}]\n",
    "\n",
    "2. 文本摘要与问答:\n",
    "\n",
    "> Pipeline: 文本摘要模型 -> 问答模型\n",
    "应用场景: 快速理解长篇文章的内容，并针对关键信息进行提问。\n",
    "示例流程:\n",
    "输入一篇新闻报道。\n",
    "文本摘要模型生成该报道的简洁摘要。\n",
    "针对摘要提出问题：“报道中提到了哪个国家？”\n",
    "问答模型根据摘要回答：“报道中提到了美国。”\n",
    "3. 机器翻译与文本生成:\n",
    "\n",
    ">Pipeline: 机器翻译模型 -> 文本生成模型\n",
    "应用场景: 将一种语言的文本翻译成另一种语言，并根据翻译结果进行进一步的文本生成，例如生成回复或摘要。\n",
    "示例流程:\n",
    "输入一句中文：“今天天气真好。”\n",
    "机器翻译模型将其翻译成英文：“The weather is really nice today.”\n",
    "文本生成模型根据翻译结果生成一句相关的回复：“Let's go for a walk!”\n",
    "4. 情感分析、文本分类与关系抽取:\n",
    "\n",
    "> Pipeline: 情感分析模型 -> 文本分类模型 -> 关系抽取模型\n",
    "应用场景: 分析文本的情感倾向，将其归类到特定主题，并识别文本中实体之间的关系。\n",
    "示例流程:\n",
    "输入一段客户反馈：“我对这家餐厅的服务非常不满，菜品也很难吃。我再也不会来了！”\n",
    "情感分析模型判断情感为“负面”。\n",
    "文本分类模型将其归类为“餐饮服务投诉”。\n",
    "关系抽取模型识别出“客户”与“餐厅”之间存在“不满”的关系，“客户”与“菜品”之间存在“难吃”的关系。\n",
    "实现 Pipeline 的常用工具和库:\n",
    "\n",
    "Hugging Face Transformers: 提供了 pipeline 类，可以轻松地加载和组合预训练模型，完成各种 NLP 任务。您只需要指定任务类型和预训练模型名称，pipeline 会自动处理分词、模型加载、推理等步骤。\n",
    "spaCy: 虽然 spaCy 的 pipeline 主要用于构建单个 NLP 模型的处理流程（例如，分词、词性标注、NER、依存句法分析），但您也可以通过自定义组件的方式将多个独立的 spaCy 模型或自定义逻辑组合成更复杂的 pipeline。\n",
    "NLTK: NLTK 提供了构建 NLP 任务模块的工具，您可以手动将不同的模块组合成 pipeline。\n",
    "自定义 Python 代码: 您可以根据具体需求，使用任何 NLP 库（如 scikit-learn、TensorFlow、PyTorch 等）构建独立的模型，并通过自定义 Python 函数将它们串联起来。\n",
    "使用 Hugging Face Transformers 的 pipeline 示例:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 文本分类：finbert、roberta-base-go_emotions、twitter-roberta-base-sentiment-latest\n",
    "- 问答：roberta-base-squad2、xlm-roberta-large-squad2、distilbert-base-cased-distilled-squad\n",
    "- 零样本分类：bart-large-mnli、mDeBERTa-v3-base-mnli-xnli\n",
    "- 翻译：t5-base、 opus-mt-zh-en、translation_en-zh\n",
    "- 总结：bart-large-cnn、led-base-book-summary\n",
    "- 文本生成：Baichuan-13B-Chat、falcon-40b、starcoder\n",
    "- 文本相似度：all-MiniLML6-v2、text2vec-large-chinese、all-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情感分析结果: [{'label': 'POSITIVE', 'score': 0.9993904829025269}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 情感分析 pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "result_sentiment = sentiment_pipeline(\"I love using the transformers library!\")\n",
    "print(f\"情感分析结果: {result_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实体: Taylor, 类型: I-PER\n",
      "实体: Beijing, 类型: I-LOC\n"
     ]
    }
   ],
   "source": [
    "# 命名实体识别 pipeline\n",
    "ner_pipeline = pipeline(\"ner\")\n",
    "result_ner = ner_pipeline(\"My name is Taylor and I live in Beijing.\")\n",
    "# print(f\"命名实体识别结果: {result_ner}\")\n",
    "# 循环输出识别结果\n",
    "for entity in result_ner:\n",
    "    print(f\"实体: {entity['word']}, 类型: {entity['entity']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问答结果: {'score': 0.963897705078125, 'start': 11, 'end': 17, 'answer': 'Taylor'}\n",
      "答案: Taylor\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 问答 pipeline\n",
    "question_answerer = pipeline(\"question-answering\", model=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "result_qa = question_answerer(question=\"What's my name?\", context=\"My name is Taylor and I live in Beijing.\")\n",
    "print(f\"问答结果: {result_qa}\")\n",
    "print(f\"答案: {result_qa['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Your max_length is set to 30, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本摘要结果: [{'summary_text': 'Taylor is a freelance writer and photographer. He lives in Beijing.'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 文本摘要 pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "text_to_summarize = \"\"\"\n",
    "My name is Taylor and I live in Beijing. I'm a freelance writer and photographer. \n",
    "\"\"\"\n",
    "result_summary = summarizer(text_to_summarize, max_length=30, min_length=5, do_sample=False)\n",
    "print(f\"文本摘要结果: {result_summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "复杂 pipeline 结果: {'sentiment': {'label': 'POSITIVE', 'score': 0.9998869895935059}, 'entities': [{'entity': 'I-ORG', 'score': 0.98976, 'index': 3, 'word': 'Apple', 'start': 13, 'end': 18}]}\n",
      "情感分析结果: {'label': 'POSITIVE', 'score': 0.9998869895935059}\n",
      "命名实体识别结果: [{'entity': 'I-ORG', 'score': 0.98976, 'index': 3, 'word': 'Apple', 'start': 13, 'end': 18}]\n",
      "实体: Apple, 类型: I-ORG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 可以将多个 pipeline 组合起来\n",
    "def complex_pipeline(text):\n",
    "    sentiment_result = sentiment_pipeline(text)[0]\n",
    "    ner_result = ner_pipeline(text)\n",
    "    return {\"sentiment\": sentiment_result, \"entities\": ner_result}\n",
    "\n",
    "complex_result = complex_pipeline(\"This amazing Apple product is fantastic!\")\n",
    "print(f\"复杂 pipeline 结果: {complex_result}\")\n",
    "print(f\"情感分析结果: {complex_result['sentiment']}\")\n",
    "print(f\"命名实体识别结果: {complex_result['entities']}\")\n",
    "\n",
    "for entity in complex_result['entities']:\n",
    "    print(f\"实体: {entity['word']}, 类型: {entity['entity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他应用\n",
    "\n",
    "- [OutfitAnyone - a Hugging Face Space by HumanAIGC](https://huggingface.co/spaces/HumanAIGC/OutfitAnyone)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
